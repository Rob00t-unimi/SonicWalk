<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SonicWalk</title>
    <style>
        body {
            margin: 0;
            padding: 0;
            font-family: Arial, sans-serif;
            background-color: #f2f2f2; /* colore di sfondo */
        }

        .navbar {
            background-color: #333;
            overflow: hidden;
            position: fixed;
            width: 100%;
            top: 0;
            z-index: 1000; /* assicura che la navbar sia sopra il contenuto */
        }

        .navbar a {
            float: left;
            display: block;
            color: white;
            text-align: center;
            padding: 14px 20px;
            text-decoration: none;
        }

        .navbar a:hover {
            background-color: #ddd;
            color: black;
        }

        .navbar a.active {
            background-color: #4CAF50;
            color: white;
        }

        /* Stili per la sezione principale */
        #readme_container {
            max-width: 800px;
            margin: 80px auto; /* centra verticalmente e orizzontalmente */
            margin-top: 0;
            padding: 20px;
            background-color: white;
            border-radius: 5px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }

        #readme_container h3 {
            margin-top: 30px;
        }

        #readme_container pre {
            background-color: rgba(0, 0, 0, 0.893);
            color: #eee;
            padding: 10px;
            border-radius: 5px;
            overflow-x: auto; /* rende la scrollbar visibile se necessario */
        }

        #readme_container code {
            color: rgb(198, 198, 198);
        }

        /* Stili per le sezioni PDF */
        #pdfContainer, #pdfCGuideContainer {
            margin-top: 20px;
            height: 500px; /* altezza predefinita */
            overflow: auto; /* rende la scrollbar visibile se necessario */
        }

        /* Stili per i titoli delle sezioni */
        h1, h2, h3 {
            color: #333;
        }

        /* Stili per la sezione di installazione */
        .installation-section {
            padding: 20px;
            background-color: white;
            border-radius: 5px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            margin-top: 20px;
        }

        /* Media Query per dispositivi di dimensioni inferiori a 768px (tablet e dispositivi mobili) */
        @media (max-width: 768px) {
            .navbar.responsive {
                position: relative;
            }

            .navbar .icon {
                display: block;
                position: absolute;
                right: 0;
                top: 0;
                padding: 14px 20px;
                color: white;
                cursor: pointer;
            }

            .navbar.responsive a {
                float: none;
                display: block;
                text-align: left;
            }

            .navbar.responsive a:not(.icon) {
                display: none;
            }

            .navbar.responsive a.active {
                background-color: #4CAF50;
                color: white;
            }
        }

        pre code {
        padding: 0;
        border: none;
        border-radius: 0;
        color: rgb(198, 198, 198)
        }
        pre {
            padding: 10px;
            background-color: rgba(0, 0, 0, 0.893);
            border-radius: 5px;
        }
        .lang-python {
            color: rgb(224, 224, 224)
        }
        .lang-python .operator {
        color: rgb(121, 188, 44)
        }
        .lang-python .string {
        color: #09c8c8; /* Colore delle stringhe */
        }
        .lang-python .object {
        color: #ff5f00; /* Colore dei numeri */
        }
        .lang-python .number {
        color: #cc00cc; /* Colore degli operatori */
        }
        .lang-python .comment {
        color: #888; /* Colore dei commenti */
        }
        .lang-python .value {
        color: #ef910e; /* Colore dei commenti */
        }

        .singlecode {
            background-color: black;
            border-radius: 2px;
            padding: 1px;
        }

    </style>
</head>
<body>

    <div class="navbar" id="navbar">
        <a href="#home" class="active">Home</a>
        <a href="#installation">Installation</a>
        <a href="#guide">Guide to using the app</a>
        <a href="#analysis">Analysis Documentation</a>
    </div>
    
    <h1 id="home" style="padding-top: 12vh; text-align: center;">SonicWalk</h1>
    <div id="readme_container">
        <h3 id="introduction">Introduction</h3>
        <p>SonicWalk is an innovative healthcare application designed to simplify and engage patients during rehabilitative exercises using real-time sonification. Developed in <strong>Python</strong> and <strong>PyQT5</strong> to ensure cross-platform compatibility, the application allows medical staff to manage patient records, monitor exercise sessions, and visualize results. It utilizes <strong>Movella MTw Awinda</strong> motion trackers and their respective APIs to gather necessary data.</p>
        
        <h3 id="features">Features</h3>
        <ul>
            <li><p><strong>Real-time Sonification</strong>: SonicWalk employs sonification techniques to provide auditory feedback during rehabilitative exercises, enhancing patient engagement, motivation, and ultimately, improving results.</p></li>
            <li><p><strong>Cross-Platform Compatibility</strong>: Built with Python and PyQT5, SonicWalk ensures compatibility across different operating systems (<em>Windows</em>, <em>Linux</em>), maximizing accessibility and usability.</p></li>
            <li><p><strong>Patient Management</strong>: Medical personnel can easily manage patients' information and exercise records through SonicWalk's intuitive interface, streamlining administrative tasks and optimizing patient care.</p></li>
            <li><p><strong>Exercise Monitoring</strong>: The application facilitates real-time monitoring of exercise sessions by healthcare providers, empowering proactive intervention and personalized guidance for patients throughout their rehabilitation journey.</p></li>
        </ul>
        
        <!-- - **Data Visualization**: SonicWalk visualizes exercise data, enabling medical staff to analyze trends, identify areas for improvement, and personalize treatment plans. -->
        
        <h3 id="about-the-project">About the Project</h3>
        <p>SonicWalk originated as part of a final internship project for a bachelor's degree in computer science. The project involved the implementation of real-time signal analysis and processing methods to detect points of interest during exercises, as well as the complete development of the graphical user interface and data management logic.</p>
        
        <h3 id="contributions">Contributions</h3>
        <p>Roberto Tallarini's Contribution:</p>
        <ul>
            <li>Expanded the original Gabriele's interface to include additional rehabilitative exercises, such as high-knee marching, backward step marching, swing, and double step.</li>
            <li>Implemented real-time signals analysis methods for each exercise, including automatic leg detection and audio feedback using the Pygame library (which provides stability and is less susceptible to interference from threads or drivers compared to Simpleaudio).</li>
            <li>Implemented a bpm estimator to calculate the medium bpm of the patient.</li>
            <li>Ideated, designed, and developed a comprehensive graphical user interface for managing patient information, records, exercise sessions, and music libraries.</li>
            <li>Conducted the porting of the original code to Windows and integrated it with the graphical user interface.</li>
            <li>Envisioned, designed, and implemented the entire user interface and data management system.</li>
            <li><a href="https://github.com/Rob00t-unimi/SonicWalk">https://github.com/Rob00t-unimi/SonicWalk</a></li>
        </ul>
        
        <p>Gabriele Esposito's Contribution:</p>
        <ul>
            <li>Developed a Python interface based on the Xsens Device API to communicate with MTw Awinda motion trackers.</li>
            <li>Implemented data recording and real-time plotting of motion tracking data.</li>
            <li>Created a gyroscope-based step detector capable of detecting steps during various walking speeds.</li>
            <li>Integrated sound reproduction for signaling step occurrences using Simpleaudio library.</li>
            <li>Assisted in the porting process to ensure cross-platform compatibility.</li>
            <li><a href="https://github.com/xyzxyzxyzxy/SonicWalk">https://github.com/xyzxyzxyzxy/SonicWalk</a></li>
        </ul>
        
        <h3 id="a-simple-python-interface-based-on-the-xsens-device-api-to-communicate-with-mtw-awinda-motion-trackers-">The simple Python interface based on the Xsens Device API to communicate with MTw Awinda motion trackers.</h3>
        <p>Data from MTw motion trackers can be recorded and returned as a Numpy.array (pitch angle). Additionally, data can be plotted in real-time in a separate process as it is received from the devices. A step detector can be spawned to detect steps while walking. Steps are detected and counted separately for each sensor (leg).</p>
        <p>The interface is created specifically to work with two MTw Awinda sensors that need to be both detected before starting the recording. Sensors produce motion tracking data in the form of Euler angles. For the specific application of step detection, pitch angle only is recorded and processed.</p>
        <p>The gyroscope-based step detector is capable of detecting steps during very slow walks and can work with a great range of speeds. To signal the occurrence of a step, a sound can be reproduced from a sample library. The sample library can be specified as a path to a directory containing .WAV or .mp3 samples. Such samples will be reproduced sequentially in lexicographic order. This gives the possibility to partition a music track into samples that will be reproduced back to back while the subject wearing the sensors is walking, at the speed the subject is walking at.</p>
        <p>A usage example can be found in the examples directory.</p>
        
        <pre><code class="lang-python">
            duration = <span class="number">90</span>
            samplesPath = <span class="string">"../sonicwalk/audio_samples/cammino_1_fase_2"</span>
            
            <span class="operator">with</span> <span class="object">mtw.MtwAwinda</span>(<span class="number">120</span>, <span class="number">19</span>, samplesPath) <span class="operator">as</span> <span class="object">mtw</span>:
                <span class="hljs-code">data = <span class="object">mtw</span>.mtwRecord(duration, plot=<span class="value">True</span>, analyze=<span class="value">True</span>, exType=<span class="number">0</span>, sensitivityLev=<span class="number">3</span>,<br> auto_detectLegs=<span class="value">False</span>, selectedLeg=<span class="value">True</span>, calculateBpm=<span class="value">False</span>, shared_data=<span class="value">None</span>, setStart=<span class="value">None</span>, sound=<span class="value">True</span>)</span>
            
            data0 = data[<span class="number">0</span>][<span class="number">0</span>]
            data1 = data[<span class="number">0</span>][<span class="number">1</span>]
            index0 = data[<span class="number">1</span>][<span class="number">0</span>]
            index1 = data[<span class="number">1</span>][<span class="number">1</span>]
            
            interestingPoints0 = data[<span class="number">2</span>][<span class="number">0</span>]
            interestingPoints1 = data[<span class="number">2</span>][<span class="number">1</span>]
            
            bpmValue = data[<span class="number">3</span>]  <span class="comment"># if calculateBpm==False will be None</span>
            </code></pre>
        
        <ul>
            <li>
                <p><strong>exType</strong> indicates the exercise to run:</p>
                <ol start="0">
                    <li>Walking</li>
                    <li>Walking in place (High Knees marching, backward step marching)</li>
                    <li>Walking in place (High Knees with sensors on the thighs)</li>
                    <li>Swing</li>
                    <li>Double step</li>
                </ol>
            </li>
            <li><strong>setStart</strong> is a callback function to call when the exercise starts.</li>
            <li><strong>CalculateBpm</strong> is a boolean indicating if the bpm must be estimated during the execution of the exercise.</li>
            <li><strong>shared_data</strong> is an optional pre-allocated SharedData object.</li>
            <li><strong>sensitivityLev</strong> is a number between 1 and 5 indicating the level of sensitivity (inversely proportional to accuracy), default: 3.</li>
            <li><strong>selectedLeg</strong> is a boolean indicating the manually selected leg (true if right leg forward, false leg forward. Defaults to None.)</li>
            <li><strong>auto_detectLegs</strong> is a boolean indicating if the legs must be automatically detected or not.</li>
            <li><strong>sound</strong> is a boolean indicating if the real-time sound must be played during the exercise.</li>
        </ul>
        
        <p>A <strong>MtwAwinda</strong> singleton object instance must be created in a <strong>with</strong> statement, ensuring proper setup of the sensors and closing. When creating the object instance, a <em>sample rate</em> and a <em>radio channel</em> must be specified together with a <em>path to the library of samples</em>. For the available sample rates and radio channels, consult the Xsense Device API documentation or the MTw Awinda motion trackers documentation. After the creation of the object, the sensors and master devices are put in <em>Measurement mode</em>, and recording can be started. To start recording, the public method <strong>mtwRecord</strong> can be called, specifying a duration value that must be a positive integer indicating the number of seconds the recording should last. Two additional flags can be provided:</p>
        
        <ul>
            <li><strong>plot</strong>: spawns a daemon that handles real-time plotting (using matplotlib).</li>
            <li><strong>analyze</strong>: spawns two daemons (one for each sensor) handling step detection and samples reproduction from the library of samples provided.</li>
        </ul>
        
        <p>The Recorded data returned by the <code class="singlecode">mtwRecord</code> function includes several components:</p>
        
        <ul>
            <li><code class="singlecode">data[0][0]</code> and <code class="singlecode">data[0][1]</code> are tuples of Numpy.arrays containing the pitch angle buffers for the two signals, respectively. The two buffers of length 72000 samples can contain roughly 10 minutes of recording (at 120Hz) after which the buffers are overwritten.</li>
            <li><code class="singlecode">data[1][0]</code> and <code class="singlecode">data[1][1]</code> represent the indices at which the recording stopped for the two signals.</li>
            <li>The 'interesting points' related to the two signals are stored in <code class="singlecode">data[2][0]</code> and <code class="singlecode">data[2][1]</code>, which are tuples of Numpy.arrays. These arrays contain the approximate indices of the two signals at which points of interest were detected.</li>
            <li><code class="singlecode">data[3]</code> contains the average beats per minute (bpm) value if the calculation was requested and the relevant data was acquired. Otherwise, it will be <code class="singlecode">None</code>.</li>
        </ul>
        
        <h1 id="installation" style="text-align: center; padding: 8vh">Installation</h1>
        
        <h2 id="semplified-installation">Simplified Installation (Executable Package)</h2>
        ...
    
        <h2 id="detailed-installation">Detailed Installation (Python Environment Setup)</h2>
        
        <h3 id="requires-and-dependencies">Requires and dependencies</h3>
        <p>Python version 3.9 is required (it is recommended to create a conda virtual environment using the python version 3.9). Installing the <em>xsensdeviceapi</em> dependency:</p>
        
        <p>Windows:</p>
        <pre><code>pip install wheels/xsensdeviceapi-2022.2.0-cp39-none-win_amd64.whl</code></pre>
        
        <p>Linux:</p>
        <pre><code>pip install wheels/xsensdeviceapi-2022.0.0-cp39-none-linux_x86_64.whl</code></pre>
        
        <h3 id="installation-of-interface-dependencies-only">Installation of the simple Python interface Dependencies</h3>
        <ul>
            <li>matplotlib</li>
            <li>pygame</li>
            <li>scipy</li>
        </ul>
        <pre><code>pip install dist/sonicwalk-1.0.0.dev1-py3-none-any.whl</code></pre>
        <pre><code>pip install matplotlib pygame scipy</code></pre>
        <pre><code>from sonicwalk import mtw</code></pre>
        
        <h3 id="installation-of-complete-gui-application-dependencies">Installation of GUI application Dependencies</h3>
        <ul>
            <li>matplotlib</li>
            <li>pygame</li>
            <li>scipy</li>
            <li>PyQt5</li>
            <li>qt_material</li>
        </ul>
        <pre><code>pip install PyQt5 matplotlib pygame qt_material scipy</code></pre>
        
        <h3 id="run-by-code">Run the GUI by Shell</h3>
        <p>Install the Complete GUI application Dependencies, then run:</p>
        <pre><code>python SonicWalk.py</code></pre>
    
    <h1 id="guide" style="text-align: center; padding: 8vh">Guide to using the app</h1>
    <div id="pdfCGuideContainer"></div>
    
    <h1 id="analysis" style="text-align: center; padding: 8vh">Analysis Documentation</h1>
    <div id="pdfContainer"></div>
    
    <script>
        var pdf_path = "../report/doc_analysis.pdf";
    
        var iframe = document.createElement('iframe');
        iframe.style.width = '100%';
        iframe.style.height = '100%';
        iframe.src = pdf_path;
    
        document.getElementById('pdfContainer').appendChild(iframe);
    
        var pdf_guide_path = "UserGuide_SonicWalk.pdf";
    
        var iframe2 = document.createElement('iframe');
        iframe2.style.width = '100%';
        iframe2.style.height = '100%';
        iframe2.src = pdf_guide_path;
    
        document.getElementById('pdfCGuideContainer').appendChild(iframe2);
    </script>

    </div>
    
    </body>
    </html>
    
    